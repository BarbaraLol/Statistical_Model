---
title: "Report_G_Group"
author: "Barbara Loletti, Andrea Esposito, Alberto Russo, Gabriel Masella, Ziyang Fu"
date: "`r Sys.Date()`"
output: html_document
---

```{r setup, include=FALSE}
# Load required libraries
#library(tidyverse)
library(mgcv)        # GAMs
library(randomForest)
library(caret)
library(Metrics)
library(ROCR)
library(gridExtra)
library(dplyr)
library(rpart)
library(rpart.plot)
library(dplyr)
library(ggplot2)

# Define likelihood_ratio_test function
likelihood_ratio_test <- function(full_model, null_model) {
  LR_statistic <- -2 * (logLik(null_model) - logLik(full_model))
  df <- df.null - df.full
  p_val <- pchisq(LR_statistic, df, lower.tail = FALSE)
  return(c(LR_statistic, p_val))
}

```

## Prime operazioni di pulizia

```{r}
# Set the number of CPU cores to use
num_cores <- parallel::detectCores()
cat("Number of CPU cores:", num_cores, "\n")

# Define the current working directory
cwd <- getwd()

# Load the data
data <- read.csv(file.path(cwd, 'health_data.csv'))

# Create a working copy to avoid modifying the original data
df <- data

# Define the list of categorical variables
categorical <- c('gender', 'cholesterol', 'gluc', 'smoke', 'alco', 'active', 'cardio')

# Replace infinite values with NA in the entire data frame
df <- as.data.frame(lapply(df, function(x) replace(x, is.infinite(x), NA)))

# Remove NaNs, although according to the data description there are no NaNs
df <- na.omit(df)

# Drop the id column and -1
df <- df[, !(names(df) %in% c('id', 'Unnamed: 0'))]

# Convert age in days
df$age <- df$age / 365.25

# Filter for impossible values for height, weight, ap_hi, ap_lo
df <- df[df$height > 130 & df$height < 220, ]
df <- df[df$weight > 30 & df$weight < 200, ]
df <- df[df$ap_hi > 60 & df$ap_hi < 240, ]
df <- df[df$ap_lo > 40 & df$ap_lo < 200, ]
df <- df[df$age < 100, ]

# Add a new column for the BMI
df$BMI <- df$weight / (df$height / 100)^2

# Filter for reasonable values for BMI
df <- df[df$BMI > 6 & df$BMI < 70, ]

# Convert all categorical variables to factors
df[categorical] <- lapply(df[categorical], as.factor)

# Reset index for reasons
df <- df[order(names(df))]

# Put the cardio column at the end
df <- df[, c(names(df)[!(names(df) %in% 'cardio')], 'cardio')]

```

## Quick dataset analysis
```{r eval=FALSE}
# Create a copy of the cleaned dataset to use for EDA
df_eda <- df

#########################
## Numerical Variables ##
#########################

par(mfrow=c(2, 2), mar=c(5, 4, 4, 2) + 0.1, oma=c(0, 0, 2, 0))
hist(df_eda$age, breaks=seq(min(df_eda$age), max(df_eda$age) + 1.5, by=1.5), col='lightblue', main='Age Distribution', xlab='Age')
hist(df_eda$height, breaks=seq(min(df_eda$height), max(df_eda$height) + 2, by=2), col='lightblue', main='Height Distribution', xlab='Height')
hist(df_eda$weight, breaks=seq(min(df_eda$weight), max(df_eda$weight) + 3, by=3), col='lightblue', main='Weight Distribution', xlab='Weight')
hist(df_eda$BMI, breaks=seq(min(df_eda$BMI), max(df_eda$BMI) + 1, by=1), col='lightblue', main='BMI Distribution', xlab='BMI')
mtext("Numeric Variables", outer=TRUE, cex=1.5)

###########################
## Categorical Variables ##
###########################

par(mfrow=c(2, 3), mar=c(5, 4, 4, 2) + 0.1, oma=c(0, 0, 2, 0))
barplot(table(df_eda$gender), col='lightblue', main='Gender Distribution', xlab='Gender')
barplot(table(df_eda$cholesterol), col='lightblue', main='Cholesterol Distribution', xlab='Cholesterol')
barplot(table(df_eda$gluc), col='lightblue', main='Glucose Distribution', xlab='Glucose')
barplot(table(df_eda$smoke), col='lightblue', main='Smoking Distribution', xlab='Smoking')
barplot(table(df_eda$alco), col='lightblue', main='Alcohol Consumption Distribution', xlab='Alcohol Consumption')
barplot(table(df_eda$active), col='lightblue', main='Physical Activity Distribution', xlab='Physical Activity')
mtext("Categorical Variables", outer=TRUE, cex=1.5)
```

```{r}
knitr::include_graphics("./numerical_variables.png")
knitr::include_graphics("./categorical_variables.png")
```


## EDA - explore data relationships

```{r eval=FALSE}
# Create a copy of the cleaned dataset to use for EDA
df_eda <- df

####################################################
## CORRELATION MATRIX WITH HIGHLIGHTED BOTTOM ROW ##
####################################################

# Create an upper triangle mask
mask_upper <- matrix(upper.tri(df_eda), nrow = ncol(df_eda), ncol = ncol(df_eda))
# Create a mask for all but the bottom row (for highlighting)
mask_not_bottom <- matrix(TRUE, nrow = ncol(df_eda), ncol = ncol(df_eda))
mask_not_bottom[nrow(mask_not_bottom), ] <- FALSE  # Unmask the bottom row

# Assuming df_eda is your dataframe
# Filter out non-numeric columns
df_numeric <- df_eda %>% select_if(is.numeric)

# Calculate the correlation matrix on the numeric dataframe
cor_matrix <- cor(df_numeric) %>% as.matrix()

# Create the heatmap
heatmap(cor_matrix,
        Rowv = NA, Colv = NA,
        col = colorRampPalette(c("blue", "white", "red"))(30),
        main = 'Enhanced Correlation Matrix with Bottom Row Highlighted',
        margins = c(5,5),
        cexRow = 1, cexCol = 1,
        symm = TRUE,
        revC = TRUE)

# Overlay with the bottom row highlighted
# Adjust 'highlight_col' to change the highlight color
# Ensure df_eda contains only numeric columns
df_numeric <- df_eda %>% select_if(is.numeric)

# Calculate the correlation matrix
cor_matrix <- cor(df_numeric)

# Define your color palette for the heatmap
highlight_col <- colorRampPalette(c("blue", "white", "red"))(30)

# Generate the heatmap
heatmap(cor_matrix,
        Rowv = NA, Colv = NA,
        col = highlight_col,
        symm = TRUE,
        revC = TRUE,
        add.expr = {
          # Add a black rectangle around the last row
          # Adjusting the rect parameters according to your specific needs
          rect(0, ncol(df_numeric), nrow(df_numeric) + 0.5, 0.5, col = 'transparent', border = 'black', lwd = 2)
        })
```


```{r eval=FALSE}
#######################################################
## DISTRIBUTION OF DATA ACCORDING TO TARGET VARIABLE ##
#######################################################

## Numerical ##
# Plot Age Distribution by Cardiovascular Disease
hist_age <- ggplot(df_eda, aes(x = age, fill = factor(cardio))) +
  geom_histogram(binwidth = 1.5, color = "white", position = "identity", alpha = 0.7) +
  labs(title = "Age Distribution by Cardiovascular Disease") +
  theme_minimal()

# Plot Height Distribution by Cardiovascular Disease
hist_height <- ggplot(df_eda, aes(x = height, fill = factor(cardio))) +
  geom_histogram(binwidth = 2, color = "white", position = "identity", alpha = 0.7) +
  labs(title = "Height Distribution by Cardiovascular Disease") +
  theme_minimal()

# Plot Weight Distribution by Cardiovascular Disease
hist_weight <- ggplot(df_eda, aes(x = weight, fill = factor(cardio))) +
  geom_histogram(binwidth = 3, color = "white", position = "identity", alpha = 0.7) +
  labs(title = "Weight Distribution by Cardiovascular Disease") +
  theme_minimal()

# Plot BMI Distribution by Cardiovascular Disease
hist_bmi <- ggplot(df_eda, aes(x = BMI, fill = factor(cardio))) +
  geom_histogram(binwidth = 1, color = "white", position = "identity", alpha = 0.7) +
  labs(title = "BMI Distribution by Cardiovascular Disease") +
  theme_minimal()

# Display the plots in a 2x2 grid
gridExtra::grid.arrange(hist_age, hist_height, hist_weight, hist_bmi, ncol = 2)

## Categorical ##

par(mfrow=c(2, 3), mar=c(5, 4, 4, 2) + 0.1, oma=c(0, 0, 2, 0))
barplot(table(df_eda$gender[df_eda$cardio == 0]), col='lightblue', main='Gender Distribution by Cardiovascular Disease (No)', xlab='Gender')
barplot(table(df_eda$gender[df_eda$cardio == 1]), col='lightcoral', main='Gender Distribution by Cardiovascular Disease (Yes)', xlab='Gender')
barplot(table(df_eda$cholesterol[df_eda$cardio == 0]), col='lightblue', main='Cholesterol Distribution by Cardiovascular Disease (No)', xlab='Cholesterol')
barplot(table(df_eda$cholesterol[df_eda$cardio == 1]), col='lightcoral', main='Cholesterol Distribution by Cardiovascular Disease (Yes)', xlab='Cholesterol')
barplot(table(df_eda$gluc[df_eda$cardio == 0]), col='lightblue', main='Glucose Distribution by Cardiovascular Disease (No)', xlab='Glucose')
barplot(table(df_eda$gluc[df_eda$cardio == 1]), col='lightcoral', main='Glucose Distribution by Cardiovascular Disease (Yes)', xlab='Glucose')
barplot(table(df_eda$smoke[df_eda$cardio == 0]), col='lightblue', main='Smoking Distribution by Cardiovascular Disease (No)', xlab='Smoking')
barplot(table(df_eda$smoke[df_eda$cardio == 1]), col='lightcoral', main='Smoking Distribution by Cardiovascular Disease (Yes)', xlab='Smoking')
barplot(table(df_eda$alco[df_eda$cardio == 0]), col='lightblue', main='Alcohol Consumption Distribution by Cardiovascular Disease (No)', xlab='Alcohol Consumption')
barplot(table(df_eda$alco[df_eda$cardio == 1]), col='lightcoral', main='Alcohol Consumption Distribution by Cardiovascular Disease (Yes)', xlab='Alcohol Consumption')
barplot(table(df_eda$active[df_eda$cardio == 0]), col='lightblue', main='Physical Activity Distribution by Cardiovascular Disease (No)', xlab='Physical Activity')
barplot(table(df_eda$active[df_eda$cardio == 1]), col='lightcoral', main='Physical Activity Distribution by Cardiovascular Disease (Yes)', xlab='Physical Activity')
mtext("Categorical Variables", outer=TRUE, cex=1.5)
```

```{r}
knitr::include_graphics("./numerical_distributions.png")
knitr::include_graphics("./categorical_distributions.png")
knitr::include_graphics("./heat_matrix.png")
```


#Class balance

```{r echo=TRUE}
# Create a copy of the cleaned dataset to use for logistic regression with balanced data
df_regression_balanced <- df

# Convert all categorical variables to integers
df_regression_balanced[, categorical] <- lapply(df_regression_balanced[, categorical], as.integer)

# Drop the "bad columns" ['gluc', 'alco', 'height', 'ap_lo', 'gender']
df_regression_balanced <- df_regression_balanced[, !(names(df_regression_balanced) %in% c('gluc', 'alco', 'height', 'ap_lo', 'gender'))]

# Find the number of samples in each class and for each categorical variable
cat_counts <- list(
  cardio = table(df_regression_balanced$cardio),
  cholesterol = table(df_regression_balanced$cholesterol),
  smoke = table(df_regression_balanced$smoke),
  active = table(df_regression_balanced$active)
)

# Print the counts
for (cat_var in names(cat_counts)) {
  cat_count <- cat_counts[[cat_var]]
  cat_name <- as.character(cat_var)
  
  #cat("```{r}\n")
  cat(cat_name, "\n")
  print(cat_count)
  #cat("```\n\n")
}

  
#cardio
#0    34673
#1    33968
#Name: count, dtype: int64
#cholesterol
#0    51469
#1     9297
#2     7875
#Name: count, dtype: int64
#smoke
#0    62598
#1     6043
#Name: count, dtype: int64
#active
#1    55150
#0    13491
#Name: count, dtype: int64
```

# Logistic regression using the linear model

```{r echo=TRUE}
# Create a copy of the cleaned dataset to use for logistic regression
df_regression <- df
summary(df)
summary(df_regression)

################
## FULL MODEL ##
################

# Create a copy for the full model
df_full <- df_regression


# Create a dummied version
#df_full <- model.matrix(~.-1, df_full)  # -1 removes intercept

# For logistic regression, statsmodels requires us to add a constant to our model
df_full$intercept <- 1.0
summary(df_full)

# Fit the logistic regression model
full_model <- glm(cardio ~  ., data = df_full, family = binomial(link = "logit"))

# Display the model's summary
summary(full_model)
```

```{r echo=TRUE}
################
## NULL MODEL ##
################

# Fit the null model
null_model <- glm(cardio ~ 1, data = df_full, binomial(link = "logit"))

summary(null_model)
```

```{r echo=TRUE}
##################
## NESTED MODEL ##
##################

# Create a copy for the nested model
nested_model <- df_regression

# Drop the unwanted columns, except age
nested_model <- nested_model[, !names(nested_model) %in% c('gluc', 'alco', 'height', 'ap_lo')]

# For logistic regression, statsmodels requires us to add a constant to our model
nested_model$intercept <- 1.0

# Fit the logistic regression model
nested_model <- glm(cardio ~ ., data = nested_model, family = binomial(link = "logit"))

# Display the model's summary
summary(nested_model)
```

```{r echo=TRUE}
#################################
## NESTED MODEL WITHOUT GENDER ##
#################################

# Create a copy for the nested model without gender
nested_model_no_gender <- df_regression

# Drop the unwanted columns
nested_model_no_gender <- nested_model_no_gender[, !names(nested_model_no_gender) %in% c('gluc', 'alco', 'height', 'ap_lo', 'gender')]

# For logistic regression, statsmodels requires us to add a constant to our model
nested_model_no_gender$intercept <- 1.0

# Fit the logistic regression model
nested_model_no_gender <- glm(cardio ~ ., data = nested_model_no_gender, family = binomial(link = "logit"))

# Display the model's summary
summary(nested_model_no_gender)

```

```{r echo=TRUE}
##############################
## ALTERNATIVE NESTED MODEL ##
##############################

# Create a copy for the alternative nested model
nested_model_alt <- df_regression

# Drop the unwanted columns
nested_model_alt <- nested_model_alt[, !names(nested_model_alt) %in% c('gender', 'height', 'BMI')]

# For logistic regression, statsmodels requires us to add a constant to our model
nested_model_alt$intercept <- 1.0

# Fit the logistic regression model
nested_model_alt <- glm(cardio ~ ., data = nested_model_alt, family = binomial(link = "logit"))

# Display the model's summary
summary(nested_model_alt)
```

```{r echo=TRUE}
########################
## COMPARE THE MODELS ##
########################

# Create a function to perform the likelihood ratio test
likelihood_ratio_test <- function(full_model, nested_model) {
  LR_statistic <- -2 * (logLik(nested_model) - logLik(full_model))
  df <- length(coef(full_model)) - length(coef(nested_model))
  p_val <- pchisq(LR_statistic, df, lower.tail = FALSE)
  return(c(LR_statistic, p_val))
}

#Accuracy of the Full model
accuracy <- function(model, data) {
  # Ensure 'data' includes an 'intercept' column set to 1
  data$intercept <- 1
  
  y_pred <- predict(model, data, type = "response")
  y_pred <- ifelse(y_pred > 0.5, 1, 0)
  y_true <- data$cardio
  return(mean(y_pred == y_true))
}

```

```{r echo=TRUE}
# Perform the likelihood ratio test
print("FULL MODEL VS NULL MODEL")
LR_statistic_p_val <- likelihood_ratio_test(full_model, null_model)
print(paste('Likelihood Ratio statistic:', LR_statistic_p_val[1]))
print(paste('p-value:', LR_statistic_p_val[2]))
```

```{r echo=TRUE}
print("NESTED MODEL VS FULL MODEL")
LR_statistic_p_val <- likelihood_ratio_test(full_model, nested_model)
```

```{r echo=TRUE}
print(paste('Likelihood Ratio statistic:', LR_statistic_p_val))

print(paste('p-value:', LR_statistic_p_val[2]))
# accuracy_value <- generics::accuracy(full_model, df_regression)

# print(paste("FULL MODEL accuracy:", accuracy_value))

# accuracy_value <- accuracy(nested_model, nested_model)
# print("NESTED MODEL accuracy", accuracy_value)
```

```{r echo=TRUE}
print("NESTED MODEL WITHOUT GENDER VS NESTED MODEL")

# LR_statistic_p_val <- likelihood_ratio_test(nested_model, nested_model_no_gender)

print(paste('Likelihood Ratio statistic:', LR_statistic_p_val[1]))

print(paste('p-value:', LR_statistic_p_val[2]))

# print("NESTED MODEL accuracy", accuracy(nested_model, nested_model))

# print("NESTED MODEL WITHOUT Gender accuracy", accuracy(nested_model_no_gender, nested_model_no_gender))

```

```{r echo=TRUE}

print("ALTERNATIVE NESTED MODEL VS NESTED MODEL")
# LR_statistic_p_val <- likelihood_ratio_test(nested_model_alt, nested_model)
print(paste('Likelihood Ratio statistic:', LR_statistic_p_val[1]))
print(paste('p-value:', LR_statistic_p_val[2]))
# print("NESTED MODEL accuracy", accuracy(nested_model, nested_model))
# print("ALTERNATIVE NESTED MODEL accuracy", accuracy(nested_model_alt, nested_model_alt))

```

## Tree
```{r echo=TRUE}
df_tree<-df
# Assuming the preliminary steps are the same, including data preparation and train-test split

# Perform a train-test split (80/20)
set.seed(42) # For reproducibility
trainIndex <- createDataPartition(df_tree$cardio, p = 0.8, list = FALSE)
df_train <- df_tree[trainIndex, ]
df_test <- df_tree[-trainIndex, ]

# Create a decision tree classifier with parameters adjusted for more branches
dt <- rpart(formula = cardio ~ ., 
            data = df_train, 
            method = "class", 
            control = rpart.control(minsplit = 10,  # Lowered to allow more splits
                                    minbucket = 5,  # Lowered to allow smaller leaf nodes
                                    cp = 0.001))    # Lowered to allow more complex tree

# If you want to visualize the tree
rpart.plot(dt)

```


## Random forest
```{r echo=TRUE}
# Create a copy of the cleaned dataset to use for feature importance
df_forest <- df
class(df)
# Assuming 'column_to_drop' is the name of the column you want to drop
column_to_drop <- "X"

# Drop the specified column
df_forest <- df_forest[, !names(df_forest) %in% column_to_drop]
summary(df_forest)


# Perform a train-test split (80/20)
trainIndex <- createDataPartition(df_forest$cardio, p = 0.8, list = FALSE)
df_train <- df_forest[trainIndex, ]
df_test <- df_forest[-trainIndex, ]

# Divide the data into features and target for training
X_train <- df_train[, !(names(df_train) %in% c('cardio'))]
y_train <- df_train$cardio

# Divide the data into features and target for testing
X_test <- df_test[, !(names(df_test) %in% c('cardio'))]
y_test <- df_test$cardio

# Capture the start time
start_time <- Sys.time()
# Create a random forest classifier
rf <- randomForest(x = X_train, y = y_train, ntree = 500, importance = TRUE, seed = 42)
# Capture the finish time
finish_time <- Sys.time()
# Calculate and print the duration
duration <- finish_time - start_time
print(paste("Duration:", duration))
print(rf)

# Get the feature importances
feature_importances <- importance(rf)
str(feature_importances)
print(feature_importances)
```

